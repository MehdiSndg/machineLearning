## 1. Matris ManipÃ¼lasyonu, Ã–zdeÄŸerler ve Ã–zvektÃ¶rlerin Makine Ã–ÄŸrenmesiyle Ä°liÅŸkisi

### ğŸ”¹ Matris ManipÃ¼lasyonu Nedir?

Matris manipÃ¼lasyonu, bir matris Ã¼zerinde yapÄ±lan temel iÅŸlemler bÃ¼tÃ¼nÃ¼dÃ¼r. Bu iÅŸlemler arasÄ±nda matris toplama, Ã§arpma, transpoz alma, determinant ve tersini hesaplama gibi iÅŸlemler yer alÄ±r. Veri analizi ve makine Ã¶ÄŸrenmesinde veriler genellikle matris formatÄ±nda temsil edilir; bu nedenle bu iÅŸlemler verinin iÅŸlenmesi, dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi ve modele uygun hale getirilmesi iÃ§in temel bir yapÄ± taÅŸÄ±nÄ± oluÅŸturur.

Ã–rneÄŸin, veri standardizasyonu, boyut indirgeme, aÄŸÄ±rlÄ±k gÃ¼ncellemeleri veya sinir aÄŸÄ± katmanlarÄ± arasÄ±nda yapÄ±lan hesaplamalar hep matris manipÃ¼lasyonlarÄ± ile gerÃ§ekleÅŸtirilir.

---

### ğŸ”¹ Ã–zdeÄŸer ve Ã–zvektÃ¶r Nedir?

**Ã–zdeÄŸer (eigenvalue)**, bir kare matrisin uyguladÄ±ÄŸÄ± dÃ¶nÃ¼ÅŸÃ¼m sonucunda bir vektÃ¶rÃ¼n yalnÄ±zca Ã¶lÃ§eklenmesini saÄŸlayan skaler bir katsayÄ±dÄ±r. **Ã–zvektÃ¶r (eigenvector)** ise bu dÃ¶nÃ¼ÅŸÃ¼mde yÃ¶nÃ¼ deÄŸiÅŸmeyen vektÃ¶rdÃ¼r. Matematiksel olarak:

> A Â· v = Î» Â· v

denkleminde `A` kare bir matris, `v` Ã¶zvektÃ¶r, `Î»` ise Ã¶zdeÄŸerdir. Bu denklemin anlamÄ±; `A` matrisinin `v` vektÃ¶rÃ¼nÃ¼ yalnÄ±zca `Î»` oranÄ±nda bÃ¼yÃ¼tÃ¼p kÃ¼Ã§Ã¼lmesidir.

---

### ğŸ”¹ Makine Ã–ÄŸrenmesi ile Ä°liÅŸkisi

Ã–zdeÄŸer ve Ã¶zvektÃ¶r kavramlarÄ±, makine Ã¶ÄŸrenmesinde Ã¶zellikle **veri dÃ¶nÃ¼ÅŸÃ¼mÃ¼** ve **boyut indirgeme** iÅŸlemlerinde kritik rol oynar. En yaygÄ±n kullanÄ±mÄ± **Principal Component Analysis (PCA)** yÃ¶ntemindedir:

- Veri setinin kovaryans matrisi oluÅŸturulur.

- Bu matrisin Ã¶zdeÄŸer ve Ã¶zvektÃ¶rleri hesaplanÄ±r.

- En yÃ¼ksek Ã¶zdeÄŸere sahip yÃ¶nler (Ã¶zvektÃ¶rler) veri iÃ§in en bilgilendirici doÄŸrultularÄ± gÃ¶sterir.

- Veri bu yÃ¶nlere projekte edilerek daha az boyutla temsil edilir.

### Bu kavramlarÄ±n kullanÄ±ldÄ±ÄŸÄ± baÅŸlÄ±ca yÃ¶ntem ve yaklaÅŸÄ±mlar:

- Principal Component Analysis (PCA)

- Spektral KÃ¼meleme (Spectral Clustering)

- Lineer diskriminant analizi (LDA)

- GÃ¶rÃ¼ntÃ¼ sÄ±kÄ±ÅŸtÄ±rma ve boyut indirgeme teknikleri

- Covariance Matrix analizleri


---

## 2. `numpy.linalg.eig` Fonksiyonunun KullanÄ±mÄ± ve Ä°ncelenmesi
  
`numpy.linalg.eig` fonksiyonu, bir kare matrisin Ã¶zdeÄŸerlerini (`eigenvalues`) ve saÄŸ Ã¶zvektÃ¶rlerini (`eigenvectors`) dÃ¶ndÃ¼rÃ¼r.  
  
---  
  
### Kaynak Kod:  
  
```python  
def eig(a):  
```  
  
`a`: Girdi olarak kare bir NumPy dizisi (matris) alÄ±r.  
  
---  
  
###  Ä°Ã§ Ä°ÅŸleyiÅŸ:  
  
#### 1. Girdi kontrolÃ¼:  
  
```python  
a, wrap = _makearray(a)  
_assert_stacked_square(a)  
_assert_finite(a)  
```  
  
- `_makearray(a)`: `a` verisini dÃ¼zgÃ¼n bir NumPy dizisine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.  
- `_assert_stacked_square(a)`: Matrisin kare (n x n) olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.  
- `_assert_finite(a)`: `a` iÃ§inde NaN veya sonsuz deÄŸer olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.  
  
  
#### 2. Veri tipi belirleme ve LAPACK signature seÃ§imi:  
  
```python  
t, result_t = _commonType(a)  
signature = 'D->DD' if isComplexType(t) else 'd->DD'  
```  
  
- `t`: veri tipi (float, complex vs.)  
- `signature`: karmaÅŸÄ±k mÄ± gerÃ§ek mi olduÄŸunu belirleyip LAPACK fonksiyonuna uygun Ã§aÄŸrÄ± yapÄ±lmasÄ±nÄ± saÄŸlar.  
  
  
#### 3. AsÄ±l hesaplama:  
  
```python  
w, vt = _umath_linalg.eig(a, signature=signature)  
```  
  
- NumPyâ€™nin C arayÃ¼zÃ¼ (`_umath_linalg`) Ã¼zerinden LAPACKâ€™in `geev` rutinini Ã§aÄŸÄ±rÄ±r.  
- `w`: Ã¶zdeÄŸerler  
- `vt`: Ã¶zvektÃ¶rlerin satÄ±r bazlÄ± hali (her sÃ¼tun bir Ã¶zvektÃ¶r)  
  
#### 4. SonuÃ§larÄ±n dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi:  
  
```python  
if not isComplexType(t) and all(w.imag == 0.0):  
 w = w.real vt = vt.real result_t = _realType(result_t)else:  
 result_t = _complexType(result_t)  
vt = vt.astype(result_t, copy=False)  
```  
  
- KarmaÅŸÄ±k olmayan durumlarda `.real` ile sadeleÅŸtirme yapÄ±lÄ±r.  
- `vt` matrisi uygun tÃ¼re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.  
  
---  
  
###  DÃ¶ndÃ¼rÃ¼len DeÄŸer:  
  
```python  
return EigResult(w.astype(result_t, copy=False), wrap(vt))  
```  
  
Yani:  
  
- `w`: Ã–zdeÄŸerleri iÃ§eren bir NumPy dizisi  
- `vt`: Her sÃ¼tunu bir Ã¶zvektÃ¶r olan bir NumPy matrisi  
- Bunlar `EigResult` adlÄ± bir `namedtuple` yapÄ±sÄ±nda dÃ¶ndÃ¼rÃ¼lÃ¼r.  
  
---  
  
###  Ã–zet:  
  
- `eig(a)`, `AÂ·v = Î»Â·v` denklemine gÃ¶re `Î»` ve `v` deÄŸerlerini bulur.  
- SayÄ±sal doÄŸrulamalar yapar.  
- Girdi matrisin yapÄ±sÄ±na gÃ¶re otomatik veri tÃ¼rÃ¼ seÃ§imi yapar.  
- YÃ¼ksek verimlilik iÃ§in LAPACK (geev) rutinini kullanÄ±r.  
- KarmaÅŸÄ±k sayÄ±larla Ã§alÄ±ÅŸmaya da uygundur.

---
## 3. NumPy ve Custom YÃ¶ntemle Hesaplanan Ã–zdeÄŸer ve Ã–zvektÃ¶rlerin KarÅŸÄ±laÅŸtÄ±rmasÄ±  
  

  
###  Ã–zdeÄŸer KarÅŸÄ±laÅŸtÄ±rmasÄ±  
  
| NumPy Ã–zdeÄŸerleri | Custom Ã–zdeÄŸerleri |  
|-------------------|--------------------|  
| 5.0               | 7.0                |  
| 3.0               | 5.0                |  
| 7.0               | 3.0                |  
  
  Her iki yÃ¶ntemde de **Ã¶zdeÄŸerler sayÄ±sal olarak aynÄ±dÄ±r**, ancak **sÄ±ralamalarÄ± farklÄ±dÄ±r**.  
- Bu fark sadece Ã§Ä±ktÄ±nÄ±n sÄ±ralama formatÄ±ndan kaynaklanmaktadÄ±r; matematiksel sonuÃ§larda bir fark yoktur.  
- Ã‡Ã¼nkÃ¼ Ã¶zdeÄŸerlerin sÄ±rasÄ± lineer cebir aÃ§Ä±sÄ±ndan Ã¶nemli deÄŸildir; vektÃ¶rlere karÅŸÄ±lÄ±k gelen sÄ±ralama doÄŸru olduÄŸu sÃ¼rece geÃ§erlidir.  
  
---  
  
###  Ã–zvektÃ¶r KarÅŸÄ±laÅŸtÄ±rmasÄ±  
  
| NumPy Ã–zvektÃ¶rleri (yaklaÅŸÄ±k)          | Custom Ã–zvektÃ¶rleri (yaklaÅŸÄ±k)         |  
|----------------------------------------|----------------------------------------|  
| [0.7071, 0.3162, 0.5883]               | [ 0.5883, -0.7071, -0.3162]            |  
| [0.    , 0.    , 0.7845]               | [ 0.7845,  0.    ,  0.    ]            |  
| [0.7071, 0.9487, 0.1961]               | [ 0.1961, -0.7071, -0.9487]            |  
  
 Ã–zvektÃ¶rler **yÃ¶n aÃ§Ä±sÄ±ndan farklÄ± gÃ¶rÃ¼nÃ¼yor** olabilir, Ã§Ã¼nkÃ¼ Ã¶zvektÃ¶rler **skaler Ã§arpanlara gÃ¶re tanÄ±msÄ±zdÄ±r**.    
  Yani bir Ã¶zvektÃ¶r `v` iÃ§in `-v` de geÃ§erli bir Ã¶zvektÃ¶rdÃ¼r.  
- NumPy tarafÄ±ndan dÃ¶ndÃ¼rÃ¼len Ã¶zvektÃ¶rler genellikle normalize edilmiÅŸtir ve yÃ¶nleri farklÄ± olabilir.  
- Ã–zellikle iÅŸaret farklarÄ± veya sÄ±ralama farklarÄ± olmasÄ± Ã¶zvektÃ¶rlerin geÃ§ersiz olduÄŸu anlamÄ±na gelmez.  
  
---  
  
###  SÃ¼re KarÅŸÄ±laÅŸtÄ±rmasÄ±  
  
| YÃ¶ntem         | SÃ¼re (saniye)        |  
|----------------|----------------------|  
| NumPy          | 0.0002094000         |  
| Custom         | 0.0003252000         |  
  
- NumPy fonksiyonu, optimize edilmiÅŸ LAPACK altyapÄ±sÄ±nÄ± kullandÄ±ÄŸÄ± iÃ§in daha hÄ±zlÄ±dÄ±r.  
- Custom fonksiyon temel Python iÅŸlemleriyle Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan biraz daha yavaÅŸtÄ±r.  
- Bu fark kÃ¼Ã§Ã¼k matrislerde belirgin olmasa da bÃ¼yÃ¼k matrislerde NumPy Ã§ok daha hÄ±zlÄ±dÄ±r.  
  
---  
  
###  Genel DeÄŸerlendirme  
  
| Kriter            | NumPy                            | Custom                              |  
|------------------|----------------------------------|-------------------------------------|  
| HÄ±z              |  Ã‡ok hÄ±zlÄ±                      |  GÃ¶receli olarak daha yavaÅŸ       |  
| KolaylÄ±k         |  Tek satÄ±r fonksiyon            |  Daha fazla kod gerektirir        |   
| Hassasiyet       |  YÃ¼ksek                         |  Benzer doÄŸruluk (kÃ¼Ã§Ã¼k farklarla)|  
  
---  
  
###  SonuÃ§  
  
Her iki yÃ¶ntem de doÄŸru sonuÃ§lar Ã¼retmiÅŸtir. NumPy yÃ¶ntemi pratik uygulamalarda tercih edilirken, custom Ã§Ã¶zÃ¼m algoritmanÄ±n mantÄ±ÄŸÄ±nÄ± anlamak ve eÄŸitim amaÃ§lÄ± Ã§alÄ±ÅŸmalarda oldukÃ§a deÄŸerlidir. Bu karÅŸÄ±laÅŸtÄ±rma, hazÄ±r kÃ¼tÃ¼phane kullanÄ±mÄ± ile temel lineer cebir kavramlarÄ±nÄ±n manuel uygulanÄ±ÅŸÄ± arasÄ±ndaki farklarÄ± net biÃ§imde ortaya koymaktadÄ±r.

---

### KullanÄ±lan Kaynaklar
[https://www.geeksforgeeks.org/eigen-values/](https://www.geeksforgeeks.org/eigen-values/)

https://www.geeksforgeeks.org/matrices-and-matrix-arithmetic-for-machine-learning/

[https://en.wikipedia.org/wiki/Principal_component_analysis](https://en.wikipedia.org/wiki/Principal_component_analysis)
